sales_millions = c(11.4, 10.2, 9, 9, 4, 4, 4, 3),
solo = c(FALSE, TRUE, TRUE, FALSE, FALSE, TRUE, TRUE, FALSE))
albums
albums$artist # pull out a specific vector
albums$artist[albums$sales_millions > 10] # subset a variable based on a logical statement. In this case, returns the artisits who issued albums with over 10 million in sales.
albums [1, ] # returns the first row of `albums`
albums [, 1] # returns the first column
albums[1:3, 2:4] # returns a new dataframe containing rows 1-3 and columns 2-4
albums[, -3] # returns a new dataframe with the original third column of `albums` removed
albums [-3, ] # returns a new dataframe with the original third row of `albums` removed
albums$sales <- albums$sales_millions*1000000
albums$language <- "English" # if you enter a single value rather than a vector, every observation will be set to that value
albums
year
albums$years_since_release <- 2018 - albums$year
# First make an empty placeholder for the new variable:
albums$decade <- NA
albums$decade[(albums$year >= 1980) & (albums$year < 1990)] <- "80s"
albums$decade[(albums$year >= 1990) & (albums$year < 2000)] <- "90s"
albums$decade[(albums$year >= 2000) & (albums$year < 2010)] <- "00s"
albums$feud <- FALSE
albums$feud[albums$artist == "2Pac"] <- TRUE
albums$feud[albums$artist == "The Notorious B.I.G."] <- TRUE
albums
born_yet <- album$year > 1996
born_yet <- albums$year > 1996
born_yet
#setwd("~/Desktop")
write.csv(albums, "albums.csv", row.names = FALSE)
albums$artist <- c("Rihanna", "Beyonce", "Taylor", "Britney", "Adele", "Cher", "Whitney", "Celine")
head(albums)
albums <- read.csv("albums.csv")
head(albums)
albums = data.frame(album = c("Speakerboxx/The Love Below", "Life After Death", "All Eyez on Me",
"Licensed to Ill", "Stankonia", "Ready to Die", "R U Still Down? Remember Me",
"Ill Communication"),
artist = c("Outkast", "The Notorious B.I.G.", "2Pac", "Beastie Boys",
"Outkast", "The Notorious B.I.G.", "2Pac", "Beastie Boys"),
year = c(2003, 1997, 1996, 1986, 2000, 1994, 1997, 1994),
sales_millions = c(11.4, 10.2, 9, 9, 4, 4, 4, 3),
solo = c(FALSE, TRUE, TRUE, FALSE, FALSE, TRUE, TRUE, FALSE))
# If you haven't yet installed dplyr, un-comment and run the following:
install.packages("dplyr")
library(dplyr)
albums2 <- albums %>%
mutate(sales = sales_millions * 1000000) %>%
filter(sales > 10000000)
result <- albums %>%                               # take initial data from `albums`, put result in `result`
mutate(sales = sales_millions * 1000000) %>%     # make a new variable `sales` by transforming `sales_millions`
group_by(artist) %>%                             # group the data by `artist`
summarize(total_sales = sum(sales)) %>%          # add up the `sales` for each artist and save in `total_sales`
arrange(desc(total_sales))                       # sort the rows in descending order of `total_sales`
head(result)
result <- albums %>%
mutate(sales = sales_millions * 1000000) %>%
group_by(solo) %>%
summarize(total_sales = sum(sales)) %>%
arrange(desc(total_sales))
head(result)
rm(list=ls())
library(dplyr)
library(ggplot2) # first `run install.packages("ggplot2")` if you haven't done so yet
stroop <- read.csv("https://raw.githubusercontent.com/lampinen/R_workshop_materials/master/data/stroop.csv")
str(stroop)
head(stroop)
summary(stroop)
qplot(x = condition, y = rt, data = stroop, geom = "boxplot")
qplot(x = rt, data = stroop, geom = "histogram")
result.rt <- stroop %>%
filter(rt > 0,
exp_stage == "test",
correct == 1) %>%
group_by(condition) %>%
summarize(mean_rt = mean(rt))
result.rt
result.acc <- stroop %>%
filter(rt>0) %>%
group_by(condition) %>%
summarize(mean_accuracy = mean(correct_response))
result.acc
result.acc <- stroop %>%
filter(exp_stage=="test") %>%
filter(rt>0) %>%
group_by(condition) %>%
summarize(mean_accuracy = mean(correct_response))
result.acc
result.acc <- stroop %>%
filter(exp_stage=="test") %>%
filter(rt>0) %>%
group_by(condition) %>%
summarize(mean_accuracy = mean(correct))
result.acc
stroop2 <- stroop %>%
select(condition, correct, exp_stage, rt, worker_id)
stroop.testtrials <- filter(stroop, exp_stage == "test")
qplot(x = correct, data = stroop.testtrials, geom = "bar")
qplot(x = correct, data = stroop.testtrials, geom = "bar", facets = stim_color~stim_word)
ggplot(data=stroop, aes(x=condition, y=rt, colour=factor(correct))) +
geom_point()+
facet_wrap(~correct)
ggplot(data=stroop, aes(x=condition, y=rt))+
geom_boxplot()
ggplot(data=stroop, aes(x=condition, y=rt, color=condition))+
geom_boxplot()
ggplot(data=stroop, aes(x=stim_word, y=rt, fill=stim_word))+
stat_summary(fun.y="mean", geom="bar", color="black")
ggplot(data=stroop, aes(x=stim_word, y=rt, fill=stim_word))+
stat_summary(fun.y="mean", geom="bar", color="black")+
stat_summary(fun.data=mean_cl_normal, geom="errorbar")
ggplot(data=stroop, aes(x=stim_word, y=rt, fill=stim_word))+
stat_summary(fun.y="mean", geom="bar", color="black")+
stat_summary(fun.data=mean_cl_normal, geom="errorbar")+
xlab("Reaction Time")+
ylab("Stimulous Word")
library(tidyverse)
library(DT) # dependency
library(ggthemes) # dependency
library(wordbankr)
install.packages("wordbankr")
library(tidyverse)
library(DT) # dependency
library(ggthemes) # dependency
library(wordbankr)
library(purrr)
library(shiny)
knitr::opts_chunk$set(echo = TRUE, cache=TRUE)
library(tidyverse)
# library(DT) # dependency
# library(ggthemes) # dependency
# library(wordbankr)
# library(purrr)
# library(shiny)
knitr::opts_chunk$set(echo = TRUE, cache=TRUE)
head(iris)
# fill me in with calls to the iris dataset that all return the same cell (third from the top, Petal Length).
iris[3,3]
# fill me in with calls to the iris dataset that all return the same cell (third from the top, Petal Length).
iris[3,3]
iris[3,"Sepal.Length"]
# fill me in with calls to the iris dataset that all return the same cell (third from the top, Petal Length).
iris[3,3]
iris[3,"Petal.Length"]
iris$Sepal.Length[3]
[3]
iris$Petal.Length[3]
iris[[Petal.Length]][3]
iris[["Petal.Length]][3]
iris[["Petal.Length"]][3]
iris[["Petal.Length"]][3]
library(tidyverse)
library(knitr)
library(papaja)
cd ~/Desktop
ls
library(yaml)
library(rmarkdown)
install.package("brms")
install.packages("brms")
install.packages("BayesFactor")
#### Import data
data <- read.csv(C:\Users\Marianna\Desktop\Dropbox\Stanford\methods\tworek2016\data)
#### Import data
data <- read.csv("C:\Users\Marianna\Desktop\Dropbox\Stanford\methods\tworek2016\data\pilotA.csv")
wd()
ls()
~
setwd(tworek2016)
setwd(C:\Users\Marianna\Desktop\Dropbox\Stanford\methods\tworek2016)
setwd(~\Marianna\Desktop\Dropbox\Stanford\methods\tworek2016)
setwd(~\Desktop\Dropbox\Stanford\methods\tworek2016)
setwd(~/Desktop/Dropbox/Stanford/methods/tworek2016)
setwd("C:\Users\Marianna\Desktop\Dropbox\Stanford\methods\tworek2016")
setwd("~/Desktop/Dropbox/Stanford/methods/tworek2016")
setwd("~/")
getwd()
setwd("C:/Users/Marianna/Desktop/Dropbox/Stanford/methods/tworek2016")
### Data Preparation
setwd("C:/Users/Marianna/Desktop/Dropbox/Stanford/methods/tworek2016")
#### Load Relevant Libraries and Functions
library(tidyverse)
#### Import data
data <- read.csv("~/data/pilotA.csv")
#### Import data
data <- read.csv("/data/pilotA.csv")
#### Import data
data <- read.csv("C:/Users/Marianna/Desktop/Dropbox/Stanford/methods/tworek2016/data/pilotA.csv")
head(data)
#### Import data
data <- read.csv("C:/Users/Marianna/Desktop/Dropbox/Stanford/methods/tworek2016/data/pilotA.csv")
head(data)
#### Data exclusion / filtering
data %>%
filter(attn == "No" | # Exclude those who didn't pay attention
IH-C1 >=5 | IH-C2 >=5 | IH-C3 <= 5 | IH-C4 <= 5) # Exclude those who failed control questions on the inherence heuristic scale
#### Data exclusion / filtering
data %>%
filter(attn == "No" | # Exclude those who didn't pay attention
"IH-C1" >=5 | "IH-C2" >=5 | "IH-C3" <= 5 | "IH-C4" <= 5) # Exclude those who failed control questions on the inherence heuristic scale
, "", x)
#### Initial data formatting
data %>% # Remove Likert scale labels
#### Initial data formatting
data %>% # Remove Likert scale labels
data %>% # Remove Likert scale labels
(lapply(function(x)
{gsub("Disagree " | "Do not agree " | "Agree somewhat " | "Agree " | "Agree very strongly" |
"Disagree strongly " | "Neither agree nor disagree " | "Agree strongly" |
"Definitely no " | "Definitely yes "
, "", x)))
data %>% # Remove Likert scale labels
lapply(function(x)
{gsub("Disagree " | "Do not agree " | "Agree somewhat " | "Agree " | "Agree very strongly" |
"Disagree strongly " | "Neither agree nor disagree " | "Agree strongly" |
"Definitely no " | "Definitely yes "
, "", x))
data %>% # Remove Likert scale labels
lapply(function(x)
{gsub("Disagree " | "Do not agree " | "Agree somewhat " | "Agree " | "Agree very strongly" |
"Disagree strongly " | "Neither agree nor disagree " | "Agree strongly" |
"Definitely no " | "Definitely yes "
, "", x)})
data %>% # Remove Likert scale labels
lapply(function(x)
{gsub("Disagree | Do not agree |Agree somewhat |Agree |Agree very strongly |
Disagree strongly |Neither agree nor disagree |Agree strongly |
Definitely no |Definitely yes "
, "", x)})
View(data)
data %>% # Remove Likert scale labels
lapply(function(x)
{gsub("Disagree |Do not agree |Agree somewhat |Agree |Agree very strongly |
Disagree strongly |Neither agree nor disagree |Agree strongly |
Definitely no |Definitely yes "
, ' ', x)})
View(data)
View(data)
#### Initial data formatting
data <- data %>% # Remove Likert scale labels
lapply(function(x)
{gsub("Disagree |Do not agree |Agree somewhat |Agree |Agree very strongly |
Disagree strongly |Neither agree nor disagree |Agree strongly |
Definitely no |Definitely yes "
, ' ', x)})
View(data)
head(data)
View(data)
data <- data %>% # Remove Likert scale labels
data.frame(lapply(function(x)
{gsub("Disagree |Do not agree |Agree somewhat |Agree |Agree very strongly |
Disagree strongly |Neither agree nor disagree |Agree strongly |
Definitely no |Definitely yes "
, ' ', x)}))
#### Import data
data <- read.csv("C:/Users/Marianna/Desktop/Dropbox/Stanford/methods/tworek2016/data/pilotA.csv")
data <- data %>% # Remove Likert scale labels
data.frame(lapply(function(x)
{gsub("Disagree |Do not agree |Agree somewhat |Agree |Agree very strongly |
Disagree strongly |Neither agree nor disagree |Agree strongly |
Definitely no |Definitely yes "
, ' ', x)}))
data <- data %>% # Remove Likert scale labels
as.data.frame(lapply(function(x)
{gsub("Disagree |Do not agree |Agree somewhat |Agree |Agree very strongly |
Disagree strongly |Neither agree nor disagree |Agree strongly |
Definitely no |Definitely yes "
, ' ', x)}))
#### Import data
data <- read.csv("C:/Users/Marianna/Desktop/Dropbox/Stanford/methods/tworek2016/data/pilotA.csv")
data %>% # Remove Likert scale labels
lapply(function(x)
{gsub("Disagree |Do not agree |Agree somewhat |Agree |Agree very strongly |
Disagree strongly |Neither agree nor disagree |Agree strongly |
Definitely no |Definitely yes "
, ' ', x)})
data <- as.data.frame(data)
View(data)
#### Import data
data <- read.csv("C:/Users/Marianna/Desktop/Dropbox/Stanford/methods/tworek2016/data/pilotA.csv")
data <- data %>% # Remove Likert scale labels
lapply(function(x)
{gsub("Disagree |Do not agree |Agree somewhat |Agree |Agree very strongly |
Disagree strongly |Neither agree nor disagree |Agree strongly |
Definitely no |Definitely yes "
, ' ', x)})
data <- as.data.frame(data)
View(data)
data <- read.csv("C:/Users/Marianna/Desktop/Dropbox/Stanford/methods/tworek2016/data/pilotA.csv")
#### Initial data formatting
data <- data %>% # Remove Likert scale labels
lapply(function(x)
{gsub("Do not agree |Agree somewhat |Agree very strongly |
Disagree strongly |Neither agree nor disagree |Agree strongly |
Agree | Disagree |
Definitely no |Definitely yes "
, ' ', x)})
data <- as.data.frame(data)
data %>%
filter(consent == "I do not agree" | # Exclude those who didn't give consent
attn == "No" | # Exclude those who didn't pay attention
"IH-C1" >=5 | "IH-C2" >=5 | "IH-C3" <= 5 | "IH-C4" <= 5) # Exclude those who failed control questions on the inherence heuristic scale
#### Initial data formatting
data %>%
slice(2)
#### Initial data formatting
data <- data %>%
slice(2)
data <- data %>% # Remove Likert scale labels
lapply(function(x)
{gsub("Do not agree |Agree somewhat |Agree very strongly |
Disagree strongly |Neither agree nor disagree |Agree strongly |
Agree | Disagree |
Definitely no |Definitely yes "
, ' ', x)})
data <- data %>%
slice(2)
data <- as.data.frame(data)
data <- data %>%
slice(2)
View(data)
#### Import data
data <- read.csv("C:/Users/Marianna/Desktop/Dropbox/Stanford/methods/tworek2016/data/pilotA.csv")
data <- data %>%
slice(2)
View(data)
#### Import data
data <- read.csv("C:/Users/Marianna/Desktop/Dropbox/Stanford/methods/tworek2016/data/pilotA.csv")
data <- data %>%
slice(1)
View(data)
#### Import data
data <- read.csv("C:/Users/Marianna/Desktop/Dropbox/Stanford/methods/tworek2016/data/pilotA.csv")
data <- data %>%
slice(-1)
View(data)
#### Import data
data <- read.csv("C:/Users/Marianna/Desktop/Dropbox/Stanford/methods/tworek2016/data/pilotA.csv")
data <- data %>%
slice(-1:-2)
View(data)
data <- data %>% #Remove 2 extra header rows
slice(-1:-2)
data <- data %>% # Remove Likert scale labels
lapply(function(x)
{gsub("Do not agree |Agree somewhat |Agree very strongly |
Disagree strongly |Neither agree nor disagree |Agree strongly |
Agree | Disagree |
Definitely no |Definitely yes "
, ' ', x)})
data <- as.data.frame(data)
data %>%
filter(consent == "I do not agree" | # Exclude those who didn't give consent
attn == "No" | # Exclude those who didn't pay attention
"IH-C1" >=5 | "IH-C2" >=5 | "IH-C3" <= 5 | "IH-C4" <= 5) # Exclude those who failed control questions on the inherence heuristic scale
data %>%
select(ResponseId, # identifier
"IH-1":"IH-15", # inherence heuristic scale
"O-1", "O-2", "O-3", "O-4", "O-5", "O-6", #ought inferences
"Gender":"English", #demographics
condition, # control (=0) or anti-inherence treatment (=1)
surveyOrder) # inherence heuristic scale first (=1) vs ought inferences first (=2)
#### Prepare data for analysis - create columns etc.
data %>%
select(ResponseId, # identifier
"O-1":"O-6", #ought inferences
"IH-1":"IH-15", # inherence heuristic scale
"Gender":"English", #demographics
condition, # control (=0) or anti-inherence treatment (=1)
surveyOrder) # inherence heuristic scale first (=1) vs ought inferences first (=2)
#### Data exclusion / filtering
data <- data %>%
filter(consent == "I do not agree" | # Exclude those who didn't give consent
attn == "No" | # Exclude those who didn't pay attention
"IH-C1" >=5 | "IH-C2" >=5 | "IH-C3" <= 5 | "IH-C4" <= 5) # Exclude those who failed control questions on the inherence heuristic scale
#### Prepare data for analysis - create columns etc.
data <- data %>%
select(ResponseId, # identifier
"IH-1":"IH-15", # inherence heuristic scale
"O-1", "O-2", "O-3", "O-4", "O-5", "O-6", #ought inferences
"Gender":"English", #demographics
condition, # control (=0) or anti-inherence treatment (=1)
surveyOrder) # inherence heuristic scale first (=1) vs ought inferences first (=2)
#### Prepare data for analysis - create columns etc.
data <- data %>%
select(ResponseId, # identifier
"IH-1":"IH-15", # inherence heuristic scale
"O-1", "O-2", "O-3", "O-4", "O-5", "O-6", #ought inferences
"Gender":"English", #demographics
condition, # control (=0) or anti-inherence treatment (=1)
surveyOrder) # inherence heuristic scale first (=1) vs ought inferences first (=2)
View(data)
#### Import data
data <- read.csv("C:/Users/Marianna/Desktop/Dropbox/Stanford/methods/tworek2016/data/pilotA.csv")
#### Initial data formatting
data <- data %>% #Remove 2 extra header rows
slice(-1:-2)
View(data)
data <- data %>% # Remove Likert scale labels
lapply(function(x)
{gsub("Do not agree |Agree somewhat |Agree very strongly |
Disagree strongly |Neither agree nor disagree |Agree strongly |
Agree | Disagree |
Definitely no |Definitely yes "
, ' ', x)})
data <- as.data.frame(data)
View(data)
{gsub("Do not agree |Agree somewhat |Agree very strongly |
Disagree strongly |Neither agree nor disagree |Agree strongly |
Agree | Disagree |
Definitely no |Definitely yes |
Really good |Really not good"
, ' ', x)})
data <- data %>% # Remove Likert scale labels
lapply(function(x)
{gsub("Do not agree |Agree somewhat |Agree very strongly |
Disagree strongly |Neither agree nor disagree |Agree strongly |
Agree | Disagree |
Definitely no |Definitely yes |
Really good |Really not good"
, ' ', x)})
data <- as.data.frame(data)
View(data)
data <- data %>%
filter(consent == "I do not agree" | # Exclude those who didn't give consent
attn == "No" | # Exclude those who didn't pay attention
"IH-C1" >=5 | "IH-C2" >=5 | "IH-C3" <= 5 | "IH-C4" <= 5) # Exclude those who failed control questions on the inherence heuristic scale
data <- data %>%
select(ResponseId, # identifier
"IH.1":"IH.15", # inherence heuristic scale
#### Data exclusion / filtering
data <- data %>%
filter(consent == "I do not agree" | # Exclude those who didn't give consent
attn == "No" | # Exclude those who didn't pay attention
"IH.C1" >=5 | "IH.C2" >=5 | "IH.C3" <= 5 | "IH.C4" <= 5) # Exclude those who failed control questions on the inherence heuristic scale
#### Prepare data for analysis - create columns etc.
data <- data %>%
#### Prepare data for analysis - create columns etc.
data <- data %>%
select(ResponseId, # identifier
"IH.1":"IH.15", # inherence heuristic scale
"O.1", "O.2", "O.3", "O.4", "O.5", "O.6", #ought inferences
"Gender":"English", #demographics
condition, # control (=0) or anti-inherence treatment (=1)
surveyOrder) # inherence heuristic scale first (=1) vs ought inferences first (=2)
#### Import data
data <- read.csv("C:/Users/Marianna/Desktop/Dropbox/Stanford/methods/tworek2016/data/pilotA.csv")
#### Initial data formatting
data <- data %>% #Remove 2 extra header rows
slice(-1:-2)
data <- data %>% # Remove Likert scale labels
lapply(function(x)
{gsub("Do not agree |Agree somewhat |Agree very strongly |
Disagree strongly |Neither agree nor disagree |Agree strongly |
Agree | Disagree |
Definitely no |Definitely yes |
Really good |Really not good"
, '', x)})
data <- as.data.frame(data)
View(data)
data <- data %>%
filter(consent == "I do not agree" | # Exclude those who didn't give consent
attn == "No" | # Exclude those who didn't pay attention
"IH.C1" >=5 | "IH.C2" >=5 | "IH.C3" <= 5 | "IH.C4" <= 5) # Exclude those who failed control questions on the inherence heuristic scale
data <- data %>%
select(ResponseId, # identifier
"IH.1":"IH.15", # inherence heuristic scale
"O.1", "O.2", "O.3", "O.4", "O.5", "O.6", #ought inferences
"Gender":"English", #demographics
condition, # control (=0) or anti-inherence treatment (=1)
surveyOrder) # inherence heuristic scale first (=1) vs ought inferences first (=2)
library(mediation)
install.packages("mediation")
library(mediation)
#### Import data
data <- read.csv("C:/Users/Marianna/Desktop/Dropbox/Stanford/methods/tworek2016/data/pilotA.csv")
#### Initial data formatting
# Remove 2 extra header rows
data <- data %>%
slice(-1:-2)
View(data)
# Add subject ID
data <- mutate(data, subject = row_number())
View(data)
data <- data %>%
lapply(function(x)
{gsub("Do not agree |Agree somewhat |Agree very strongly |
Disagree strongly |Neither agree nor disagree |Agree strongly |
Agree | Disagree |
Definitely no |Definitely yes |
Really good |Really not good"
, '', x)})
data <- as.data.frame(data)
data <- data %>%
filter(consent == "I do not agree" | # Exclude those who didn't give consent
attn == "No" | # Exclude those who didn't pay attention
"IH.C1" >=5 | "IH.C2" >=5 | "IH.C3" <= 5 | "IH.C4" <= 5) # Exclude those who failed control questions on the inherence heuristic scale
data <- data %>%
select(subject, # subject ID
"IH.1":"IH.15", # inherence heuristic scale
"O.1", "O.2", "O.3", "O.4", "O.5", "O.6", # ought inferences
"Gender":"English", # demographics
condition, # control (=0) or anti-inherence treatment (=1)
surveyOrder) # inherence heuristic scale first (=1) vs ought inferences first (=2)
#### Prepare data for analysis - create columns etc.
# select relevant columns
View(data)
data <- data %>%
select(subject, # subject ID
"IH.1", "IH.15", # inherence heuristic scale
"O.1", "O.2", "O.3", "O.4", "O.5", "O.6", # ought inferences
"Gender", "English", # demographics
condition, # control (=0) or anti-inherence treatment (=1)
surveyOrder) # inherence heuristic scale first (=1) vs ought inferences first (=2)
